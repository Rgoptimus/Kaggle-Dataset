{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:03.984383Z",
     "iopub.status.busy": "2022-02-16T14:45:03.983919Z",
     "iopub.status.idle": "2022-02-16T14:45:04.024110Z",
     "shell.execute_reply": "2022-02-16T14:45:04.023205Z",
     "shell.execute_reply.started": "2022-02-16T14:45:03.984260Z"
    }
   },
   "source": [
    "### This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 - Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.026160Z",
     "iopub.status.busy": "2022-02-16T14:45:04.025789Z",
     "iopub.status.idle": "2022-02-16T14:45:04.085302Z",
     "shell.execute_reply": "2022-02-16T14:45:04.084668Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.026116Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/credit-card-customers/BankChurners.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset owner suggested, we should drop the last two columns before doing anything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.086509Z",
     "iopub.status.busy": "2022-02-16T14:45:04.086292Z",
     "iopub.status.idle": "2022-02-16T14:45:04.095031Z",
     "shell.execute_reply": "2022-02-16T14:45:04.094367Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.086478Z"
    }
   },
   "outputs": [],
   "source": [
    "# slice the DataFrame, excluding 2 last columns, and reassign to 'df'\n",
    "df = df.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Preview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.097084Z",
     "iopub.status.busy": "2022-02-16T14:45:04.096730Z",
     "iopub.status.idle": "2022-02-16T14:45:04.130045Z",
     "shell.execute_reply": "2022-02-16T14:45:04.129500Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.096930Z"
    }
   },
   "outputs": [],
   "source": [
    "# set option to show all columns without truncation\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "# Preview the top 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.131488Z",
     "iopub.status.busy": "2022-02-16T14:45:04.130972Z",
     "iopub.status.idle": "2022-02-16T14:45:04.135720Z",
     "shell.execute_reply": "2022-02-16T14:45:04.135044Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.131457Z"
    }
   },
   "outputs": [],
   "source": [
    "# find rows and columns count\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.137143Z",
     "iopub.status.busy": "2022-02-16T14:45:04.136523Z",
     "iopub.status.idle": "2022-02-16T14:45:04.173255Z",
     "shell.execute_reply": "2022-02-16T14:45:04.172699Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.137114Z"
    }
   },
   "outputs": [],
   "source": [
    "# see dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.174779Z",
     "iopub.status.busy": "2022-02-16T14:45:04.174212Z",
     "iopub.status.idle": "2022-02-16T14:45:04.219231Z",
     "shell.execute_reply": "2022-02-16T14:45:04.218387Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.174747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find unique values for each columns\n",
    "for col in df:\n",
    "    uniq = df[col].value_counts()\n",
    "    print(uniq, '\\n==============\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Dataset Features Description\n",
    "|No. | Column Name | Description | Data Type | Feature Type | Non-Null Value | Unique Values|\n",
    "|---|---|---|---|---|---|---|\n",
    "|1| CLIENTNUM | Client number. Unique identifier for the customer holding the account | int | Nominal | 10127 | *(10127 unique ID)*|\n",
    "|2| Attrition_Flag | Internal event (customer activity) variable - if the account is closed then 1 else 0 | str | Nominal | 10127 | Existing Customer, Attrited Customer |\n",
    "|3| Customer_Age | Demographic variable - Customer's Age in Years | int | Ratio | 10127 | *varied numerical* |\n",
    "|4| Gender | Demographic variable - M=Male, F=Female | str | Nominal | 10127 | M, F |\n",
    "|5| Dependent_count | Demographic variable - Number of dependents | int | Ratio | 10127 | 0, 1, 2, 3, 4, 5 | \n",
    "|6| Education_Level | Demographic variable - Educational Qualification of the account holder | str | Ordinal | 10127 | Unknown, Uneducated, High School, College, Graduate, Post-Graduate, Doctorate |\n",
    "|7| Marital_Status | Demographic variable - Marital Status of the account holder | str | Nominal | 10127 | Unknown, Single, Married, Divorced |\n",
    "|8| Income_Category | Demographic variable - Annual Income Category of the account holder | str | Ordinal | 10127 | Unknown, Less than $40 K, $40K – $60K, $60K – $80K, $80K – $120K, $120K +|\n",
    "|9| Card_Category | Product Variable - Type of Card | str | Ordinal | 10127 | Blue, Silver, Gold, Platinum |\n",
    "|10| Months_on_book | Period of relationship with bank | int | Ratio | 10127 | *varied numerical* |\n",
    "|11| Total_Relationship_Count | Total no. of products held by the customer | int | Ratio | 10127 | 0, 1, 2, 3, 4, 5, 6 |\n",
    "|12| Months_Inactive_12_mon | No. of months inactive in the last 12 months | int | Ratio | 10127 | 0, 1, 2, 3, 4, 5, 6 |\n",
    "|13| Contacts_Count_12_mon | No. of Contacts in the last 12 months | int | Ratio | 10127 | 0, 1, 2, 3, 4, 5, 6 |\n",
    "|14| Credit_Limit | Credit Limit on the Credit Card | float | Ratio | 10127 | *varied numerical* |\n",
    "|15| Total_Revolving_Bal | Total Revolving Balance on the Credit Card | int | Ratio | 10127 | *varied numerical* |\n",
    "|16| Avg_Open_To_Buy | Open to Buy Credit Line (Average of last 12 months) | float | Ratio | 10127 | *varied numerical* |\n",
    "|17| Total_Amt_Chng_Q4_Q1 | Change in Transaction Amount (Q4 over Q1) | float | Ratio | 10127 | *varied numerical* |\n",
    "|18| Total_Trans_amt | Total Transaction Amount (Last 12 months) | int | Ratio | 10127 | *varied numerical* |\n",
    "|19| Total_Trans_Ct | Total Transaction Count (Last 12 months) | int | Ratio | 10127 | *varied numerical* |\n",
    "|20| Total_Ct_Chng_Q4_Q1 | Change in Transaction Count (Q4 over Q1) | float | Ratio | 10127 | *varied numerical* |\n",
    "|21| Avg_Utilization_Ratio | Average Card Utilization Ratio | float | Ratio | 10127 | *varied numerical* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 - Identifying Activities\n",
    "Based on our initial Data Understanding stage, we can identify some activities that needs to be done on the dataset:\n",
    "1. **Remove Unnecessary Features**: the dataset might have some features that are unnecessary for our modelling, that is features that cannot be used as predictor. Remove them before doing EDA\n",
    "2. **Handle Missing Value**: make sure that the dataset doesn't have any missing value\n",
    "3. **Exploratory Data Analysis**: explore the features statistically, and use visualization to get a better view of the data\n",
    "4. **Handle Categorical Data**: categorical data needs to be encoded before modelling\n",
    "5. **Handle Numerical Data**: scale the numerical data with Standardization or Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 - EDA & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Unnecessary Feature Removal\n",
    "Before processing further, we need to remove features that cannot be used on modelling.\n",
    "The *CLIENTNUM* feature contains unique ID for every customer so it can not be used as Predictor (input) for the Target (output), and should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.220884Z",
     "iopub.status.busy": "2022-02-16T14:45:04.220627Z",
     "iopub.status.idle": "2022-02-16T14:45:04.237147Z",
     "shell.execute_reply": "2022-02-16T14:45:04.236060Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.220856Z"
    }
   },
   "outputs": [],
   "source": [
    "# slice the DataFrame, excluding CLIENTNUM column at index 0, and reassign to 'df'\n",
    "df = df.iloc[:,1:]\n",
    "\n",
    "# see the updated df information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all relevant features, each with their correct data type, let's define which features are numerical and categorical and assign each to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.239304Z",
     "iopub.status.busy": "2022-02-16T14:45:04.238764Z",
     "iopub.status.idle": "2022-02-16T14:45:04.248231Z",
     "shell.execute_reply": "2022-02-16T14:45:04.247241Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.239260Z"
    }
   },
   "outputs": [],
   "source": [
    "#define categorical columns\n",
    "cat_cols = list(df.select_dtypes('object'))\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.253320Z",
     "iopub.status.busy": "2022-02-16T14:45:04.252422Z",
     "iopub.status.idle": "2022-02-16T14:45:04.261531Z",
     "shell.execute_reply": "2022-02-16T14:45:04.260883Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.253275Z"
    }
   },
   "outputs": [],
   "source": [
    "#define numerical columns\n",
    "num_cols = list(df.select_dtypes(['int64','float64']))\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Missing Value Check\n",
    "Make Sure that the data has no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.263095Z",
     "iopub.status.busy": "2022-02-16T14:45:04.262495Z",
     "iopub.status.idle": "2022-02-16T14:45:04.277781Z",
     "shell.execute_reply": "2022-02-16T14:45:04.276959Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.263064Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** there is no missing value found on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Target Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Target Feature (output) that we want to predict is *Attrition_Flag*, which has two unique values, that is 'Existing Customer' and 'Attrited Customer'. Before doing the exploration, encode those values into 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.279554Z",
     "iopub.status.busy": "2022-02-16T14:45:04.278919Z",
     "iopub.status.idle": "2022-02-16T14:45:04.286981Z",
     "shell.execute_reply": "2022-02-16T14:45:04.286420Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.279522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Attrition_Flag\n",
    "df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, \n",
    "                                                 'Attrited Customer':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use visualization in exploring the features of the dataset, so we need to import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:04.288713Z",
     "iopub.status.busy": "2022-02-16T14:45:04.288296Z",
     "iopub.status.idle": "2022-02-16T14:45:05.353496Z",
     "shell.execute_reply": "2022-02-16T14:45:05.352866Z",
     "shell.execute_reply.started": "2022-02-16T14:45:04.288684Z"
    }
   },
   "outputs": [],
   "source": [
    "# import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('pastel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Target Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:05.355849Z",
     "iopub.status.busy": "2022-02-16T14:45:05.354897Z",
     "iopub.status.idle": "2022-02-16T14:45:05.508101Z",
     "shell.execute_reply": "2022-02-16T14:45:05.507151Z",
     "shell.execute_reply.started": "2022-02-16T14:45:05.355805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data \n",
    "attr_count = df['Attrition_Flag'].value_counts()\n",
    "attr_label = df['Attrition_Flag'].value_counts().index\n",
    "\n",
    "# Plot\n",
    "fig,ax = plt.subplots(figsize=(7,5))\n",
    "# pie plot\n",
    "ax.pie(attr_count, explode=(0.1,0), labels=attr_label, autopct='%.2f%%', startangle=90)\n",
    "ax.set_title('Attrition_Flag', fontsize=15)\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we have 16.07% of customers that attrited/churned, or 1627 out of 10127."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Predictor Features Exploration\n",
    "Now, let's have a look at the other features, that will be used as predictors for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Numerical Predictor Features\n",
    "First, define the numerical predictors, which are all the numerical features we defined earlier. Assign it to a variable, as it will be used later for slicing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:05.510417Z",
     "iopub.status.busy": "2022-02-16T14:45:05.510105Z",
     "iopub.status.idle": "2022-02-16T14:45:05.522242Z",
     "shell.execute_reply": "2022-02-16T14:45:05.521157Z",
     "shell.execute_reply.started": "2022-02-16T14:45:05.510377Z"
    }
   },
   "outputs": [],
   "source": [
    "# define numerical predictors\n",
    "num_pred = num_cols\n",
    "num_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:05.529335Z",
     "iopub.status.busy": "2022-02-16T14:45:05.523945Z",
     "iopub.status.idle": "2022-02-16T14:45:05.598433Z",
     "shell.execute_reply": "2022-02-16T14:45:05.597901Z",
     "shell.execute_reply.started": "2022-02-16T14:45:05.529268Z"
    }
   },
   "outputs": [],
   "source": [
    "# describe the statistics of numerical predictors\n",
    "num_stat = df[num_pred].describe().transpose().reset_index()\n",
    "num_stat.rename(columns={'index': 'feature'}, inplace=True)\n",
    "num_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.2. Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:05.599741Z",
     "iopub.status.busy": "2022-02-16T14:45:05.599424Z",
     "iopub.status.idle": "2022-02-16T14:45:08.710387Z",
     "shell.execute_reply": "2022-02-16T14:45:08.709504Z",
     "shell.execute_reply.started": "2022-02-16T14:45:05.599715Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=14, figsize=(7,70))  #each axes size=7x5\n",
    "\n",
    "i=0\n",
    "\n",
    "for col in num_pred:\n",
    "    sns.kdeplot(x=df[col], fill=True, alpha=1, ax=ax[i])\n",
    "    ax[i].set_xlabel(' ')\n",
    "    ax[i].set_ylabel(' ')\n",
    "    ax[i].set_title(col, fontsize=12)\n",
    "   # ax[i].text(0.05, 0.005, 'test')  # how to add skewness text to plot?\n",
    "    i=i+1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:08.712629Z",
     "iopub.status.busy": "2022-02-16T14:45:08.712135Z",
     "iopub.status.idle": "2022-02-16T14:45:08.730442Z",
     "shell.execute_reply": "2022-02-16T14:45:08.729538Z",
     "shell.execute_reply.started": "2022-02-16T14:45:08.712585Z"
    }
   },
   "outputs": [],
   "source": [
    "# check skewness of distribution\n",
    "skew = []\n",
    "for col in num_pred:\n",
    "    skew.append(round(df[col].skew(),3))\n",
    "\n",
    "num_dist = pd.DataFrame({'feature':num_pred, 'skewness':skew})\n",
    "num_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that have skewness between -0.05 and 0.05 are assumed to have gaussian distribution, which are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:08.731989Z",
     "iopub.status.busy": "2022-02-16T14:45:08.731644Z",
     "iopub.status.idle": "2022-02-16T14:45:08.742564Z",
     "shell.execute_reply": "2022-02-16T14:45:08.741736Z",
     "shell.execute_reply.started": "2022-02-16T14:45:08.731944Z"
    }
   },
   "outputs": [],
   "source": [
    "gauss_feat = list(num_dist.query('skewness < 0.05 & skewness > -0.05')['feature'])\n",
    "gauss_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1.3. Numerical Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:08.744542Z",
     "iopub.status.busy": "2022-02-16T14:45:08.743836Z",
     "iopub.status.idle": "2022-02-16T14:45:09.623030Z",
     "shell.execute_reply": "2022-02-16T14:45:09.622400Z",
     "shell.execute_reply.started": "2022-02-16T14:45:08.744490Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare figure\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Correlation between All Numerical Feature', size=15)\n",
    "\n",
    "# create mask\n",
    "mask = np.triu(np.ones_like(df.corr()))\n",
    "# create colormap\n",
    "colormap = sns.color_palette(\"Blues\")\n",
    "# plot heatmap\n",
    "sns.heatmap(df.corr(), annot=True, cmap=colormap, mask=mask)\n",
    "# sns.heatmap(df.corr(), annot=True, mask=mask)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that some feature are highly correlated, such as:\n",
    "* *Avg_Open_To_Buy* and *Credit_Limit*, (1)\n",
    "* *Total_Trans_Ct* and *Total_Trans_Amt*, (0.81)\n",
    "* *Months_on_book* and *Customer_Age*, (0.79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.4. Numerical-Target Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:09.624627Z",
     "iopub.status.busy": "2022-02-16T14:45:09.624247Z",
     "iopub.status.idle": "2022-02-16T14:45:09.646578Z",
     "shell.execute_reply": "2022-02-16T14:45:09.645739Z",
     "shell.execute_reply.started": "2022-02-16T14:45:09.624585Z"
    }
   },
   "outputs": [],
   "source": [
    "# initiate empty list\n",
    "tg_num_corr = []\n",
    "\n",
    "# loop to fill tg_num_corr with each columns vs Target correlation coefficient\n",
    "for col in num_pred:\n",
    "    tg_num_corr.append(df[col].corr(df['Attrition_Flag']))\n",
    "\n",
    "# create as DataFrame\n",
    "tg_num_df = pd.DataFrame({'Numerical_Predictors': num_pred,\n",
    "                          'Correlation_w_Target': tg_num_corr })\n",
    "\n",
    "# sort the DataFrame by the absolute value of their correlation coefficient, descending\n",
    "tg_num_df = tg_num_df.sort_values(by='Correlation_w_Target', key=abs, ascending=False).reset_index(drop=True)\n",
    "\n",
    "# call the DataFrame\n",
    "tg_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:09.647884Z",
     "iopub.status.busy": "2022-02-16T14:45:09.647684Z",
     "iopub.status.idle": "2022-02-16T14:45:09.910712Z",
     "shell.execute_reply": "2022-02-16T14:45:09.910144Z",
     "shell.execute_reply.started": "2022-02-16T14:45:09.647859Z"
    }
   },
   "outputs": [],
   "source": [
    "# display as figure\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.barplot(x=tg_num_df['Correlation_w_Target'], y=tg_num_df['Numerical_Predictors'], color='#a2c9f4')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.title('Numerical-Target Relationship', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.5. Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Box Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:09.912220Z",
     "iopub.status.busy": "2022-02-16T14:45:09.911741Z",
     "iopub.status.idle": "2022-02-16T14:45:11.248559Z",
     "shell.execute_reply": "2022-02-16T14:45:11.247643Z",
     "shell.execute_reply.started": "2022-02-16T14:45:09.912172Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the figure\n",
    "fig, ax = plt.subplots(ncols=1, nrows=14, figsize=(7,70)) #each axes size=7x5\n",
    "# initiate variable\n",
    "i=0\n",
    "# loop\n",
    "for col in num_pred:\n",
    "    sns.boxplot(data=df, x=col, ax=ax[i], palette='pastel')\n",
    "    ax[i].set_xlabel(' ')\n",
    "    ax[i].set_ylabel(' ')\n",
    "    ax[i].set_title(col, fontsize=12)\n",
    "    i=i+1\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Outliers Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the outliers from our dataset. We will use two methods to find the outliers:\n",
    "* Inner Fence, and\n",
    "* Outer Fence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Inner Fence**<br>\n",
    "The lower boundary of this method is defined by *Q1 - (1.5 * IQR)*, and the upper boundary is defined by *Q1 + (1.5 * IQR)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.249818Z",
     "iopub.status.busy": "2022-02-16T14:45:11.249620Z",
     "iopub.status.idle": "2022-02-16T14:45:11.423930Z",
     "shell.execute_reply": "2022-02-16T14:45:11.423304Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.249794Z"
    }
   },
   "outputs": [],
   "source": [
    "# outliers of each feature using Inner Fence\n",
    "\n",
    "# initiate empty dictionary and list for the loop\n",
    "outlier_dict_if = {}          #dict feature and all outliers\n",
    "outlier_dict_unique_if = {}   #dict feature and unique outliers\n",
    "# loop each features\n",
    "for col in num_pred:\n",
    "    # find upper and lower bound of each features using inner fence\n",
    "    stats = df[col].describe()\n",
    "    q1, q3 = stats['25%'], stats['75%']\n",
    "    iqr = q3-q1\n",
    "    lower_bound_if = q1 - (1.5 * iqr)\n",
    "    upper_bound_if = q3 + (1.5 * iqr)\n",
    "    \n",
    "    # set a condition: add data that are outside upper-lower boundary to dict\n",
    "    # initiate empty list\n",
    "    outlier_list_if = []\n",
    "    outlier_list_unique_if = []\n",
    "    for x in df[col]:\n",
    "        if ((x > upper_bound_if) or (x < lower_bound_if)):\n",
    "            outlier_list_if.append(x)\n",
    "            # if the value is not already in list\n",
    "            if x not in outlier_list_unique_if:\n",
    "                outlier_list_unique_if.append(x)\n",
    "        # append the list to dictionaries\n",
    "        outlier_dict_if['{}'.format(col)] = outlier_list_if\n",
    "        outlier_dict_unique_if['{}'.format(col)] = outlier_list_unique_if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.425322Z",
     "iopub.status.busy": "2022-02-16T14:45:11.424797Z",
     "iopub.status.idle": "2022-02-16T14:45:11.440580Z",
     "shell.execute_reply": "2022-02-16T14:45:11.439815Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.425289Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see outliers from each features    \n",
    "for k,v in outlier_dict_if.items():\n",
    "    print(k, 'outliers (inner fence):')\n",
    "    print(v)\n",
    "    print('count:',len(v))\n",
    "    print('====\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.443647Z",
     "iopub.status.busy": "2022-02-16T14:45:11.443180Z",
     "iopub.status.idle": "2022-02-16T14:45:11.458763Z",
     "shell.execute_reply": "2022-02-16T14:45:11.458029Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.443615Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see unique outliers from each features    \n",
    "for k,v in outlier_dict_unique_if.items():\n",
    "    print(k, 'unique outlier (inner fence):')\n",
    "    print(v)\n",
    "    print('count:',len(v))\n",
    "    print('====\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.459995Z",
     "iopub.status.busy": "2022-02-16T14:45:11.459779Z",
     "iopub.status.idle": "2022-02-16T14:45:11.474533Z",
     "shell.execute_reply": "2022-02-16T14:45:11.473658Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.459968Z"
    }
   },
   "outputs": [],
   "source": [
    "## create as dataframe\n",
    "# initiate empty lists\n",
    "outlier_list_count_if = []\n",
    "outlier_unique_count_if = []\n",
    "\n",
    "# loop\n",
    "for k, v in outlier_dict_if.items():\n",
    "    outlier_list_count_if.append(len(v))\n",
    "for k, v in outlier_dict_unique_if.items():\n",
    "    outlier_unique_count_if.append(len(v))\n",
    "\n",
    "# create dataframe\n",
    "outlier_df_if = pd.DataFrame({'feature': num_pred,\n",
    "                           'outlier_count_if': outlier_list_count_if,\n",
    "                           'unique_outlier_count_if': outlier_unique_count_if})\n",
    "outlier_df_if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how many rows will be removed if we were to remove all of these outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.479138Z",
     "iopub.status.busy": "2022-02-16T14:45:11.478901Z",
     "iopub.status.idle": "2022-02-16T14:45:11.535259Z",
     "shell.execute_reply": "2022-02-16T14:45:11.534393Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.479109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Outlier based on IQR for features in num_pred_outlier, using inner fence\n",
    "after_removal_if = df\n",
    "\n",
    "for col in num_pred:\n",
    "    stats = df[col].describe()\n",
    "    q1, q3 = stats['25%'], stats['75%']\n",
    "    iqr = q3-q1\n",
    "    lower_bound_if = q1 - (1.5 * iqr)\n",
    "    upper_bound_if = q3 + (1.5 * iqr)\n",
    "    \n",
    "    after_removal_if = after_removal_if[(after_removal_if[col] >= lower_bound_if) & (after_removal_if[col] <= upper_bound_if)]\n",
    "\n",
    "# percentage removed\n",
    "removed_if = 100*(df.shape[0] - after_removal_if.shape[0])/df.shape[0]\n",
    "print('Percentage of removed rows: {}%'.format(round(removed_if,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Outer Fence**<br>\n",
    "The lower boundary of this method is defined by *Q1 - (3 * IQR)*, and the upper boundary is defined by *Q1 + (3 * IQR)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.537589Z",
     "iopub.status.busy": "2022-02-16T14:45:11.536662Z",
     "iopub.status.idle": "2022-02-16T14:45:11.705440Z",
     "shell.execute_reply": "2022-02-16T14:45:11.704747Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.537544Z"
    }
   },
   "outputs": [],
   "source": [
    "# outliers of each feature using Outer Fence\n",
    "\n",
    "# initiate empty dictionary and list for the loop\n",
    "outlier_dict_of = {}          #dict feature and all outliers\n",
    "outlier_dict_unique_of = {}   #dict feature and unique outliers\n",
    "# loop each features\n",
    "for col in num_pred:\n",
    "    # find upper and lower bound of each features using outer fence\n",
    "    stats = df[col].describe()\n",
    "    q1, q3 = stats['25%'], stats['75%']\n",
    "    iqr = q3-q1\n",
    "    lower_bound_of = q1 - (3 * iqr)\n",
    "    upper_bound_of = q3 + (3 * iqr)\n",
    "    \n",
    "    # set a condition: add data that are outside upper-lower boundary to dict\n",
    "    # initiate empty list\n",
    "    outlier_list_of = []\n",
    "    outlier_list_unique_of = []\n",
    "    for x in df[col]:\n",
    "        if ((x > upper_bound_of) or (x < lower_bound_of)):\n",
    "            outlier_list_of.append(x)\n",
    "            # if the value is not already in list\n",
    "            if x not in outlier_list_unique_of:\n",
    "                outlier_list_unique_of.append(x)\n",
    "        # append the list to dictionaries\n",
    "        outlier_dict_of['{}'.format(col)] = outlier_list_of\n",
    "        outlier_dict_unique_of['{}'.format(col)] = outlier_list_unique_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.707789Z",
     "iopub.status.busy": "2022-02-16T14:45:11.706885Z",
     "iopub.status.idle": "2022-02-16T14:45:11.725004Z",
     "shell.execute_reply": "2022-02-16T14:45:11.724202Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.707743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see outliers from each features    \n",
    "for k,v in outlier_dict_of.items():\n",
    "    print(k, 'outliers (outer fence):')\n",
    "    print(v)\n",
    "    print('count:',len(v))\n",
    "    print('====\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.727129Z",
     "iopub.status.busy": "2022-02-16T14:45:11.726192Z",
     "iopub.status.idle": "2022-02-16T14:45:11.741257Z",
     "shell.execute_reply": "2022-02-16T14:45:11.740482Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.727081Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see unique outliers from each features    \n",
    "for k,v in outlier_dict_unique_of.items():\n",
    "    print(k, 'unique outlier (outer fence):')\n",
    "    print(v)\n",
    "    print('count:',len(v))\n",
    "    print('====\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.743785Z",
     "iopub.status.busy": "2022-02-16T14:45:11.743534Z",
     "iopub.status.idle": "2022-02-16T14:45:11.756675Z",
     "shell.execute_reply": "2022-02-16T14:45:11.755734Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.743755Z"
    }
   },
   "outputs": [],
   "source": [
    "## create as dataframe\n",
    "# initiate empty lists\n",
    "outlier_list_count_of = []\n",
    "outlier_unique_count_of = []\n",
    "\n",
    "# loop\n",
    "for k, v in outlier_dict_of.items():\n",
    "    outlier_list_count_of.append(len(v))\n",
    "for k, v in outlier_dict_unique_of.items():\n",
    "    outlier_unique_count_of.append(len(v))\n",
    "\n",
    "# create dataframe\n",
    "outlier_df_of = pd.DataFrame({'feature': num_pred,\n",
    "                           'outlier_count_of': outlier_list_count_of,\n",
    "                           'unique_outlier_count_of': outlier_unique_count_of})\n",
    "outlier_df_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how many rows will be removed if we were to remove all of these outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.758116Z",
     "iopub.status.busy": "2022-02-16T14:45:11.757889Z",
     "iopub.status.idle": "2022-02-16T14:45:11.818367Z",
     "shell.execute_reply": "2022-02-16T14:45:11.817410Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.758089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Outlier based on IQR for features in num_pred_outlier, using outer fence\n",
    "after_removal_of = df\n",
    "\n",
    "for col in num_pred:\n",
    "    stats = df[col].describe()\n",
    "    q1, q3 = stats['25%'], stats['75%']\n",
    "    iqr = q3-q1\n",
    "    lower_bound_of = q1 - (3 * iqr)\n",
    "    upper_bound_of = q3 + (3 * iqr)\n",
    "    \n",
    "    after_removal_of = after_removal_of[(after_removal_of[col] >= lower_bound_of) & (after_removal_of[col] <= upper_bound_of)]\n",
    "\n",
    "# percentage removed\n",
    "removed_of = 100*(df.shape[0] - after_removal_of.shape[0])/df.shape[0]\n",
    "print('Percentage of removed rows: {}%'.format(round(removed_of,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. Categorical Predictor Features\n",
    "First, define the categorical predictors, which are the categorical features except 'Attrition_Flag'. Assign it to a variable, as it will be used later for slicing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.819563Z",
     "iopub.status.busy": "2022-02-16T14:45:11.819353Z",
     "iopub.status.idle": "2022-02-16T14:45:11.825363Z",
     "shell.execute_reply": "2022-02-16T14:45:11.824600Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.819538Z"
    }
   },
   "outputs": [],
   "source": [
    "#define categorical predictors\n",
    "cat_pred = cat_cols[1:]\n",
    "cat_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2.1. Descriptive Statistics\n",
    "Let's take a look at the descriptive statistics of the categorical predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.826964Z",
     "iopub.status.busy": "2022-02-16T14:45:11.826736Z",
     "iopub.status.idle": "2022-02-16T14:45:11.858015Z",
     "shell.execute_reply": "2022-02-16T14:45:11.857182Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.826937Z"
    }
   },
   "outputs": [],
   "source": [
    "# describe the statistics of categorical predictors\n",
    "cat_stat = df[cat_pred].describe().transpose().reset_index()\n",
    "cat_stat.rename(columns={'index': 'feature'}, inplace=True)\n",
    "cat_stat['top_freq_percentage'] = cat_stat['freq']/cat_stat['count']*100\n",
    "cat_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2.2 Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:11.859697Z",
     "iopub.status.busy": "2022-02-16T14:45:11.859432Z",
     "iopub.status.idle": "2022-02-16T14:45:12.067891Z",
     "shell.execute_reply": "2022-02-16T14:45:12.067307Z",
     "shell.execute_reply.started": "2022-02-16T14:45:11.859669Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "sns.barplot(x=cat_stat['unique'], y=cat_stat['feature'], orient='h')\n",
    "ax.set_xlabel(' ')\n",
    "ax.set_ylabel(' ')\n",
    "ax.set_title('Categorical Predictors Cardinality', fontsize=12)\n",
    "# add value labels\n",
    "for j,v in enumerate(cat_stat['unique']):\n",
    "    ax.text(v,j,str(v))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no problem in cardinality, as each features has relatively few unique value counts. Too much unique values on categorical features would cause problems in one-hot encoding, as we could end up having too many features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2.3. Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:12.069767Z",
     "iopub.status.busy": "2022-02-16T14:45:12.069038Z",
     "iopub.status.idle": "2022-02-16T14:45:13.179559Z",
     "shell.execute_reply": "2022-02-16T14:45:13.178725Z",
     "shell.execute_reply.started": "2022-02-16T14:45:12.069711Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare the figure and axes\n",
    "fig, ax = plt.subplots(ncols=1, nrows=5, figsize=(7,25))  #each axes size=7x5\n",
    "\n",
    "i=0  # initialize i for iteration\n",
    "\n",
    "# iterate plotting\n",
    "for col in cat_pred:\n",
    "    catcount = df[col].value_counts()\n",
    "    catlabel = df[col].value_counts().index\n",
    "    \n",
    "    # for more than two unique values\n",
    "    if len(df[col].value_counts()) > 2:\n",
    "        # bar plot\n",
    "        catcount = df[col].value_counts()\n",
    "        catlabel = df[col].value_counts().index\n",
    "        ax[i].barh(catlabel, catcount)\n",
    "        # add value label\n",
    "        for j,v in enumerate(catcount):\n",
    "            ax[i].text(v,j,str(v))\n",
    "            continue\n",
    "        ax[i].set_title(col, fontsize=15)\n",
    "    \n",
    "    # for less than 2 unique values\n",
    "    else:\n",
    "        #pie plot\n",
    "        ax[i].pie(catcount, labels=catlabel, autopct='%1.1f%%', startangle=90)\n",
    "        ax[i].set_title(col, fontsize=15)\n",
    "        \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of 'Platinum' and 'Silver' *Card_Category* are too small compared to other category. We could either delete, or merge it with another category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2.4. Categorical-Target Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:13.180865Z",
     "iopub.status.busy": "2022-02-16T14:45:13.180656Z",
     "iopub.status.idle": "2022-02-16T14:45:14.023290Z",
     "shell.execute_reply": "2022-02-16T14:45:14.022389Z",
     "shell.execute_reply.started": "2022-02-16T14:45:13.180839Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=5, figsize=(7,25))  #each axes size=7x5\n",
    "\n",
    "i=0\n",
    "\n",
    "for col in cat_pred:\n",
    "    sns.countplot(x=df[col], hue=df['Attrition_Flag'], fill=True, alpha=1, ax=ax[i])\n",
    "    ax[i].set_xlabel(' ')\n",
    "    ax[i].set_ylabel(' ')\n",
    "    #ax[i].xaxis.set_ticks_params(labelsize=14)\n",
    "    #ax[i].ticks_params(left=False, labelleft=False)\n",
    "    #ax[i].set_ylabel(col, fontsize=16)\n",
    "    #ax[i].bar_label(ax[i].containers[0], size='12')\n",
    "    ax[i].set_title('Attrition_Flag - {}'.format(col), fontsize=12)\n",
    "    # add value label\n",
    "    #for j,v in enumerate(?):\n",
    "    #    ax[i].text(v,j,str(v))\n",
    "    #    continue\n",
    "    i=i+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.024608Z",
     "iopub.status.busy": "2022-02-16T14:45:14.024361Z",
     "iopub.status.idle": "2022-02-16T14:45:14.028253Z",
     "shell.execute_reply": "2022-02-16T14:45:14.027621Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.024574Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy df to a new variable that will be processed\n",
    "data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Numerical Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Outlier Removal\n",
    "Outlier should be removed to clean our data. Previously, we have calculate the percentage of removed rows using two outlier methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.030118Z",
     "iopub.status.busy": "2022-02-16T14:45:14.029256Z",
     "iopub.status.idle": "2022-02-16T14:45:14.040985Z",
     "shell.execute_reply": "2022-02-16T14:45:14.039810Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.030073Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Inner Fence, rows removed: {}%'.format(round(removed_if, 2)))\n",
    "print('Outer Fence, rows removed: {}%'.format(round(removed_of, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing too much rows would make our data not representative of the actual dataset. Normally, it should only be around 5% to 10%. Therefore, we will use the Outer Fence method to find and remove the outliers as it only remove 8.77% or the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.042637Z",
     "iopub.status.busy": "2022-02-16T14:45:14.042184Z",
     "iopub.status.idle": "2022-02-16T14:45:14.055975Z",
     "shell.execute_reply": "2022-02-16T14:45:14.055316Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.042602Z"
    }
   },
   "outputs": [],
   "source": [
    "# recall the outliers summary of Outer Fence method\n",
    "outlier_df_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.057757Z",
     "iopub.status.busy": "2022-02-16T14:45:14.056985Z",
     "iopub.status.idle": "2022-02-16T14:45:14.124440Z",
     "shell.execute_reply": "2022-02-16T14:45:14.123616Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.057711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove outliers based on outer fence boundary\n",
    "for col in num_pred:\n",
    "    stats = data[col].describe()\n",
    "    q1, q3 = stats['25%'], stats['75%']\n",
    "    iqr = q3-q1\n",
    "    lower_bound = q1 - (3 * iqr)\n",
    "    upper_bound = q3 + (3 * iqr)\n",
    "    \n",
    "    data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "\n",
    "# Check updated dataframe\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.126068Z",
     "iopub.status.busy": "2022-02-16T14:45:14.125762Z",
     "iopub.status.idle": "2022-02-16T14:45:14.132697Z",
     "shell.execute_reply": "2022-02-16T14:45:14.131856Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.126016Z"
    }
   },
   "outputs": [],
   "source": [
    "# updated dataframe\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1.2. Remove Highly Correlated Predictors\n",
    "For two predictor features that are highly correlated, we just need one of them to be used on model as they are assumed to have  similar predictive power. Let's recalculate their correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.134892Z",
     "iopub.status.busy": "2022-02-16T14:45:14.134317Z",
     "iopub.status.idle": "2022-02-16T14:45:14.927177Z",
     "shell.execute_reply": "2022-02-16T14:45:14.926395Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.134849Z"
    }
   },
   "outputs": [],
   "source": [
    "### recalculate correlation after outlier removal\n",
    "# prepare figure\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Correlation between All Numerical Feature After Outlier Removal', size=15)\n",
    "\n",
    "# create mask to cover the upper triangle of the heatmap\n",
    "mask = np.triu(np.ones_like(data.corr()))\n",
    "# create colormap\n",
    "colormap = sns.color_palette(\"Blues\")\n",
    "# plot heatmap\n",
    "sns.heatmap(data.corr(), annot=True, cmap=colormap, mask=mask)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Avg_Open_To_Buy* and *Credit_Limit* are highly correlated (1). It means that an increase on one would increase the other, so we only need one of them and we can safely drop the other. We choose to drop one features that have higher correlation to target variabel *Attrition_Flag*, that is **Avg_Open_To_Buy** (0.021 vs -0.0034)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.929004Z",
     "iopub.status.busy": "2022-02-16T14:45:14.928501Z",
     "iopub.status.idle": "2022-02-16T14:45:14.947039Z",
     "shell.execute_reply": "2022-02-16T14:45:14.946121Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.928962Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop one of the highly correlated feature\n",
    "dropped = ['Avg_Open_To_Buy']\n",
    "data = data.drop(dropped, axis=1)\n",
    "\n",
    "# updated DataFrame\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.948659Z",
     "iopub.status.busy": "2022-02-16T14:45:14.948325Z",
     "iopub.status.idle": "2022-02-16T14:45:14.956042Z",
     "shell.execute_reply": "2022-02-16T14:45:14.955317Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.948628Z"
    }
   },
   "outputs": [],
   "source": [
    "# redefine numerical predictors list by removing dropped features\n",
    "### 1st way\n",
    "#num_pred_process = num_pred\n",
    "#for i in dropped:\n",
    "#    num_pred_process.remove(i)\n",
    "### 2nd way    \n",
    "num_pred_process = [x for x in num_pred if x not in dropped]\n",
    "\n",
    "print(*num_pred_process, sep='\\n')\n",
    "print('\\nCount:', len(num_pred_process))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Scaling\n",
    "The technique used to scale numerical data depends on the type of its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.957634Z",
     "iopub.status.busy": "2022-02-16T14:45:14.957221Z",
     "iopub.status.idle": "2022-02-16T14:45:14.974380Z",
     "shell.execute_reply": "2022-02-16T14:45:14.973747Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.957581Z"
    }
   },
   "outputs": [],
   "source": [
    "# check skewness of updated dataframe\n",
    "skew_upd = []\n",
    "for col in num_pred_process:\n",
    "    skew_upd.append(round(data[col].skew(),3))\n",
    "\n",
    "num_dist_upd = pd.DataFrame({'feature':num_pred_process, 'skewness':skew_upd})\n",
    "num_dist_upd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that have skewness between -0.05 and 0.05 are assumed to have gaussian distribution, which are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.975972Z",
     "iopub.status.busy": "2022-02-16T14:45:14.975581Z",
     "iopub.status.idle": "2022-02-16T14:45:14.983820Z",
     "shell.execute_reply": "2022-02-16T14:45:14.982999Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.975942Z"
    }
   },
   "outputs": [],
   "source": [
    "std_pred = list(num_dist.query('skewness < 0.05 & skewness > -0.05')['feature'])\n",
    "std_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:14.985362Z",
     "iopub.status.busy": "2022-02-16T14:45:14.985134Z",
     "iopub.status.idle": "2022-02-16T14:45:15.119796Z",
     "shell.execute_reply": "2022-02-16T14:45:15.118964Z",
     "shell.execute_reply.started": "2022-02-16T14:45:14.985332Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3.1. Standardization\n",
    "Standardization is used to scale features that are assumed to have gaussian distribution (skewness between -0.05 and 0.05), which are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.123264Z",
     "iopub.status.busy": "2022-02-16T14:45:15.122948Z",
     "iopub.status.idle": "2022-02-16T14:45:15.130002Z",
     "shell.execute_reply": "2022-02-16T14:45:15.129375Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.123234Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature to be standardized\n",
    "std_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.131419Z",
     "iopub.status.busy": "2022-02-16T14:45:15.130902Z",
     "iopub.status.idle": "2022-02-16T14:45:15.147721Z",
     "shell.execute_reply": "2022-02-16T14:45:15.146774Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.131386Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaler\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(data[std_pred])\n",
    "data[std_pred] = std_scaler.transform(data[std_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.149175Z",
     "iopub.status.busy": "2022-02-16T14:45:15.148955Z",
     "iopub.status.idle": "2022-02-16T14:45:15.170596Z",
     "shell.execute_reply": "2022-02-16T14:45:15.169792Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.149147Z"
    }
   },
   "outputs": [],
   "source": [
    "data[std_pred].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3.2. Normalization\n",
    "If the data doesn't have a gaussian distribution, use Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.171673Z",
     "iopub.status.busy": "2022-02-16T14:45:15.171468Z",
     "iopub.status.idle": "2022-02-16T14:45:15.177887Z",
     "shell.execute_reply": "2022-02-16T14:45:15.177228Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.171648Z"
    }
   },
   "outputs": [],
   "source": [
    "# define features to be normalized\n",
    "mm_pred = num_pred_process\n",
    "for i in std_pred:\n",
    "    mm_pred.remove(i)\n",
    "mm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.179620Z",
     "iopub.status.busy": "2022-02-16T14:45:15.179003Z",
     "iopub.status.idle": "2022-02-16T14:45:15.195827Z",
     "shell.execute_reply": "2022-02-16T14:45:15.195107Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.179587Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(data[mm_pred])\n",
    "data[mm_pred] = mm_scaler.transform(data[mm_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.198139Z",
     "iopub.status.busy": "2022-02-16T14:45:15.197284Z",
     "iopub.status.idle": "2022-02-16T14:45:15.238299Z",
     "shell.execute_reply": "2022-02-16T14:45:15.237386Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.198095Z"
    }
   },
   "outputs": [],
   "source": [
    "data[mm_pred].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Categorical Data Handling\n",
    "ML models cannot understand categorical data type, thus we need to encode the categorical value into numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Label Encoding\n",
    "Ordinal and binary data are encoded with Label Encoding, which encodes their value into a range of integer starting from 0.\n",
    "<br> Note that on *Card_Category*, the count for 'Platinum' and 'Gold' are relatively small. Thus, we shall merge them with *Card_Category* 'Silver'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name | Type | Value | Encoded Value |\n",
    "|---|---|---|---|\n",
    "| Education_Level | Ordinal | <ul><li>Unknown</li><li>Uneducated</li><li>High School</li><li>College</li><li>Graduate</li><li>Post-Graduate</li><li>Doctorate</li></ul> | <ul><li>0</li><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li><li>6</li></ul> |\n",
    "| Income_Category | Ordinal | <ul><li>Unknown</li><li>Less than $40K $</li><li>$40K - $60K</li><li>$60K - $80K</li><li>$80K - $120K</li><li>$120K +$</li></ul> | <ul><li>0</li><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li></ul> |\n",
    "| Card_Category | Ordinal | <ul><li>Blue</li><li>Silver</li><li>Gold</li><li>Platinum</li></ul> | <ul><li>0</li><li>1</li><li>1</li><li>1</li></ul> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.240230Z",
     "iopub.status.busy": "2022-02-16T14:45:15.239938Z",
     "iopub.status.idle": "2022-02-16T14:45:15.247256Z",
     "shell.execute_reply": "2022-02-16T14:45:15.246519Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.240191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Education_Level\n",
    "data['Education_Level'] = data['Education_Level'].map({'Unknown':0,\n",
    "                                                       'Uneducated':1,\n",
    "                                                       'High School':2,\n",
    "                                                       'College':3,\n",
    "                                                       'Graduate':4,\n",
    "                                                       'Post-Graduate':5,\n",
    "                                                       'Doctorate':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.249349Z",
     "iopub.status.busy": "2022-02-16T14:45:15.248838Z",
     "iopub.status.idle": "2022-02-16T14:45:15.258273Z",
     "shell.execute_reply": "2022-02-16T14:45:15.257501Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.249308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Income_Category\n",
    "data['Income_Category'] = data['Income_Category'].map({'Unknown':0,\n",
    "                                                       'Less than $40K':1,\n",
    "                                                       '$40K - $60K':2,\n",
    "                                                       '$60K - $80K':3,\n",
    "                                                       '$80K - $120K':4,\n",
    "                                                       '$120K +':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.260326Z",
     "iopub.status.busy": "2022-02-16T14:45:15.259803Z",
     "iopub.status.idle": "2022-02-16T14:45:15.269652Z",
     "shell.execute_reply": "2022-02-16T14:45:15.268805Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.260286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Card_Category\n",
    "data['Card_Category'] = data['Card_Category'].map({'Blue':0,\n",
    "                                                   'Silver': 1,\n",
    "                                                   'Gold':1,\n",
    "                                                   'Platinum':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.271393Z",
     "iopub.status.busy": "2022-02-16T14:45:15.271105Z",
     "iopub.status.idle": "2022-02-16T14:45:15.298968Z",
     "shell.execute_reply": "2022-02-16T14:45:15.298138Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.271353Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. One Hot Encoding\n",
    "*Gender* and *Marital_Status* cannot be ordered like ordinal, thus we encode them by using One Hot Encoding using Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.301377Z",
     "iopub.status.busy": "2022-02-16T14:45:15.300968Z",
     "iopub.status.idle": "2022-02-16T14:45:15.313242Z",
     "shell.execute_reply": "2022-02-16T14:45:15.312636Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.301345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode Gender and Marital_Status\n",
    "data = pd.get_dummies(data, columns=['Gender', 'Marital_Status'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.315069Z",
     "iopub.status.busy": "2022-02-16T14:45:15.314318Z",
     "iopub.status.idle": "2022-02-16T14:45:15.338150Z",
     "shell.execute_reply": "2022-02-16T14:45:15.337232Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.315031Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Train-Test Split\n",
    "Now, let's take a look at the updated features of our dataset. At this point we can split the dataset into predictors (input) and target (output) to be used on the next stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.339761Z",
     "iopub.status.busy": "2022-02-16T14:45:15.339544Z",
     "iopub.status.idle": "2022-02-16T14:45:15.353007Z",
     "shell.execute_reply": "2022-02-16T14:45:15.352442Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.339735Z"
    }
   },
   "outputs": [],
   "source": [
    "#define X (predictors) and y (target)\n",
    "_X = data.drop('Attrition_Flag', axis=1)  # input variables\n",
    "_y = data.Attrition_Flag                  # output variable\n",
    "\n",
    "# all features\n",
    "feature_all = _X.columns\n",
    "print(*feature_all, sep='\\n')\n",
    "print('\\nFeature Count:', len(feature_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of model evaluation, we shall split the dataset into Train and Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.354541Z",
     "iopub.status.busy": "2022-02-16T14:45:15.353853Z",
     "iopub.status.idle": "2022-02-16T14:45:15.405026Z",
     "shell.execute_reply": "2022-02-16T14:45:15.404390Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.354499Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.406579Z",
     "iopub.status.busy": "2022-02-16T14:45:15.405973Z",
     "iopub.status.idle": "2022-02-16T14:45:15.424908Z",
     "shell.execute_reply": "2022-02-16T14:45:15.424080Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.406536Z"
    }
   },
   "outputs": [],
   "source": [
    "# split train and test \n",
    "_X_train, _X_test, _y_train, _y_test = train_test_split(_X, _y, test_size=0.25, random_state=0, stratify=_y)\n",
    "print('Train set shape:', _X_train.shape)\n",
    "print('Test set shape:', _X_test.shape)\n",
    "print('')\n",
    "print('Proportional class distribution in train data:\\n'+ str(_y_train.value_counts() / _y_train.count()), '\\n')\n",
    "print('Proportional class distribution in test data:\\n'+ str(_y_test.value_counts() / _y_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Feature Selection\n",
    "Feature selection is used to avoid complexity in our models. We can use only relevant features, or features that would provide optimal result. We have already done Correlation Statistics technique where we dropped one of two features that are having high correlation. \n",
    "\n",
    "Another technique in Feature Selection is by using algorithm. In this stage, we will select the optimal features by using LASSO regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.426234Z",
     "iopub.status.busy": "2022-02-16T14:45:15.426031Z",
     "iopub.status.idle": "2022-02-16T14:45:15.578849Z",
     "shell.execute_reply": "2022-02-16T14:45:15.577931Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.426209Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required libaries\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. Find the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.580136Z",
     "iopub.status.busy": "2022-02-16T14:45:15.579913Z",
     "iopub.status.idle": "2022-02-16T14:45:15.599316Z",
     "shell.execute_reply": "2022-02-16T14:45:15.598444Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.580109Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "select_1 = SelectFromModel(Lasso(alpha=0.008, random_state=0))\n",
    "\n",
    "#train the model\n",
    "select_1.fit(_X_train, _y_train)\n",
    "\n",
    "# get support from the model\n",
    "print('FEATURE COUNT:',select_1.get_support().sum())\n",
    "print('')\n",
    "# selected feature\n",
    "feature_lasso_1 = _X_train.columns[(select_1.get_support())]\n",
    "print('SELECTED FEATURES:')\n",
    "print(*feature_lasso_1, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.601725Z",
     "iopub.status.busy": "2022-02-16T14:45:15.600876Z",
     "iopub.status.idle": "2022-02-16T14:45:15.623648Z",
     "shell.execute_reply": "2022-02-16T14:45:15.622834Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.601671Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "select_2 = SelectFromModel(Lasso(alpha=0.004, random_state=0))\n",
    "\n",
    "#train the model\n",
    "select_2.fit(_X_train, _y_train)\n",
    "\n",
    "# get support from the model\n",
    "print('FEATURE COUNT:',select_2.get_support().sum())\n",
    "print('')\n",
    "# selected feature\n",
    "feature_lasso_2 = _X_train.columns[(select_2.get_support())]\n",
    "print('SELECTED FEATURES:')\n",
    "print(*feature_lasso_2, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3rd Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.625768Z",
     "iopub.status.busy": "2022-02-16T14:45:15.625228Z",
     "iopub.status.idle": "2022-02-16T14:45:15.649373Z",
     "shell.execute_reply": "2022-02-16T14:45:15.648520Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.625722Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "select_3 = SelectFromModel(Lasso(alpha=0.002, random_state=0))\n",
    "\n",
    "#train the model\n",
    "select_3.fit(_X_train, _y_train)\n",
    "\n",
    "# get support from the model\n",
    "print('FEATURE COUNT:',select_3.get_support().sum())\n",
    "print('')\n",
    "\n",
    "# selected feature\n",
    "feature_lasso_3 = _X_train.columns[(select_3.get_support())]\n",
    "print('SELECTED FEATURES:')\n",
    "print(*feature_lasso_3, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. Try the Features on a Model\n",
    "We shall compare the model with all features, and the model with selected features. Let's define a function to calculate the score of a Logistic Regression model from our _X and _y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.651561Z",
     "iopub.status.busy": "2022-02-16T14:45:15.651041Z",
     "iopub.status.idle": "2022-02-16T14:45:15.661414Z",
     "shell.execute_reply": "2022-02-16T14:45:15.660518Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.651517Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_reg_scores(name, feat):\n",
    "    # modelling\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    result = model.fit(_X_train[feat], _y_train)\n",
    "\n",
    "    # prediction\n",
    "    predicted = result.predict(_X_test[feat])\n",
    "    predicted_proba = result.predict_proba(_X_test[feat])\n",
    "    predicted_proba = [i[1] for i in predicted_proba]\n",
    "\n",
    "    # evaluation\n",
    "    accuracy = accuracy_score(y_true=_y_test, y_pred=predicted)\n",
    "    fscore = f1_score(y_true=_y_test, y_pred=predicted)\n",
    "    aucscore = roc_auc_score(y_true=_y_test, y_score=predicted_proba)\n",
    "\n",
    "    #print\n",
    "    print(\"Logistic Regression Accuracy ({}):\".format(name), accuracy)\n",
    "    print(\"Logistic Regression F-Score ({}):\".format(name), fscore)\n",
    "    print(\"Logistic Regression AUC ({}):\".format(name), aucscore)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.663526Z",
     "iopub.status.busy": "2022-02-16T14:45:15.662997Z",
     "iopub.status.idle": "2022-02-16T14:45:15.786093Z",
     "shell.execute_reply": "2022-02-16T14:45:15.785229Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.663477Z"
    }
   },
   "outputs": [],
   "source": [
    "# model with all features\n",
    "log_reg_scores(name='all', feat=feature_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.788275Z",
     "iopub.status.busy": "2022-02-16T14:45:15.787735Z",
     "iopub.status.idle": "2022-02-16T14:45:15.845186Z",
     "shell.execute_reply": "2022-02-16T14:45:15.844327Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.788228Z"
    }
   },
   "outputs": [],
   "source": [
    "# model with lasso 1st iteration\n",
    "log_reg_scores(name='1st lasso', feat=feature_lasso_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.847373Z",
     "iopub.status.busy": "2022-02-16T14:45:15.846846Z",
     "iopub.status.idle": "2022-02-16T14:45:15.909522Z",
     "shell.execute_reply": "2022-02-16T14:45:15.908649Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.847329Z"
    }
   },
   "outputs": [],
   "source": [
    "# model with lasso 2nd iteration\n",
    "log_reg_scores(name='2nd lasso', feat=feature_lasso_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.911729Z",
     "iopub.status.busy": "2022-02-16T14:45:15.911179Z",
     "iopub.status.idle": "2022-02-16T14:45:15.981373Z",
     "shell.execute_reply": "2022-02-16T14:45:15.980527Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.911682Z"
    }
   },
   "outputs": [],
   "source": [
    "# model with lasso 3rd iteration\n",
    "log_reg_scores(name='3rd lasso', feat=feature_lasso_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3. Conclusion\n",
    "* The model with features selected by 1st iteration (alpha=0.008) has lower scores compared to the model with all features\n",
    "* The model with features selected by 2nd iteration (alpha=0.004) has almost similar, even slightly higher scores compared to the model with all features\n",
    "* The model with features selected by 3rd iteration (alpha=0.002) has almost similar scores compared to the model with 2nd iteration features, but the 3rd iteration has more features (13) compared to the 2nd iteration (10)\n",
    "\n",
    "Thus, we will use the features selected by the 2nd iteration, as it produces similar result but with less than a half of the original features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:53:20.683012Z",
     "iopub.status.busy": "2022-02-16T16:53:20.682702Z",
     "iopub.status.idle": "2022-02-16T16:53:20.693924Z",
     "shell.execute_reply": "2022-02-16T16:53:20.693204Z",
     "shell.execute_reply.started": "2022-02-16T16:53:20.682983Z"
    }
   },
   "outputs": [],
   "source": [
    "# redefine input and output variables\n",
    "X = _X[feature_lasso_2]\n",
    "X_train = _X_train[feature_lasso_2]\n",
    "y_train = _y_train\n",
    "X_test = _X_test[feature_lasso_2]\n",
    "y_test = _y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:15.993441Z",
     "iopub.status.busy": "2022-02-16T14:45:15.992898Z",
     "iopub.status.idle": "2022-02-16T14:45:16.012526Z",
     "shell.execute_reply": "2022-02-16T14:45:16.011626Z",
     "shell.execute_reply.started": "2022-02-16T14:45:15.993395Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5 - Modelling\n",
    "We have all the features we need, now let's move on to the last stage, developing the model. We will use visualization to display the confusion matrix and ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:16.014691Z",
     "iopub.status.busy": "2022-02-16T14:45:16.014152Z",
     "iopub.status.idle": "2022-02-16T14:45:16.020841Z",
     "shell.execute_reply": "2022-02-16T14:45:16.020000Z",
     "shell.execute_reply.started": "2022-02-16T14:45:16.014645Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required library\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:16.022943Z",
     "iopub.status.busy": "2022-02-16T14:45:16.022427Z",
     "iopub.status.idle": "2022-02-16T14:45:16.037346Z",
     "shell.execute_reply": "2022-02-16T14:45:16.036015Z",
     "shell.execute_reply.started": "2022-02-16T14:45:16.022898Z"
    }
   },
   "outputs": [],
   "source": [
    "### define functions to display visualization\n",
    "\n",
    "# confusion matrix visualization\n",
    "def confusion_matrix_heatmap(conf_mat):\n",
    "    conf_mat_prop = conf_mat / conf_mat.sum()\n",
    "    conf_mat_prop = pd.DataFrame(conf_mat_prop)\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    _ = sns.heatmap(conf_mat_prop, annot = True, cmap = \"Blues\", vmin = 0, vmax = 1)\n",
    "    _.set_title(\"Proportional Confusion Matrix\")\n",
    "    _.set(xlabel = \"Predicted Value\", ylabel = \"Actual Value\")\n",
    "    \n",
    "    return plt.show()\n",
    "\n",
    "# AUC visualization\n",
    "def auc_visualization(y_test_fold, predicted_proba):\n",
    "    # Create no-skill model\n",
    "    ns_proba = [0 for _ in range(len(y_test_fold))]\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_true = y_test_fold, y_score = ns_proba)\n",
    "\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_true = y_test_fold, y_score = predicted_proba)\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    _ = plt.plot(ns_fpr, ns_tpr, linestyle = \"--\", label = \"No-skill model\")\n",
    "    _ = plt.plot(model_fpr, model_tpr, marker = \".\", label = \"Best model\")\n",
    "    _ = plt.title(\"Receiver Operating Characteristic Curve\")\n",
    "    _ = plt.xlabel('False Positive Rate')\n",
    "    _ = plt.ylabel('True Positive Rate')\n",
    "    _ = plt.legend()\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1. Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:45:16.039854Z",
     "iopub.status.busy": "2022-02-16T14:45:16.039277Z",
     "iopub.status.idle": "2022-02-16T14:45:16.733042Z",
     "shell.execute_reply": "2022-02-16T14:45:16.732104Z",
     "shell.execute_reply.started": "2022-02-16T14:45:16.039808Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "lg_model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# train the model\n",
    "lg_result = lg_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "lg_predicted = lg_result.predict(X_test)\n",
    "lg_predicted_proba = lg_result.predict_proba(X_test)\n",
    "lg_predicted_proba = [i[1] for i in lg_predicted_proba]\n",
    "\n",
    "# confusion matrix\n",
    "lg_conf_mat = confusion_matrix(y_true = y_test, y_pred = lg_predicted)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(lg_conf_mat)\n",
    "print('\\n\\n')\n",
    "# display confusion matrix heatmap\n",
    "confusion_matrix_heatmap(lg_conf_mat)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Evaluation\n",
    "lg_accuracy = accuracy_score(y_true = y_test, y_pred = lg_predicted)\n",
    "lg_fscore = f1_score(y_true = y_test, y_pred = lg_predicted)\n",
    "lg_roc_auc = roc_auc_score(y_true = y_test, y_score = lg_predicted_proba)\n",
    "print(\"Logistic Regression Accuracy:\", round(lg_accuracy,3))\n",
    "print(\"Logistic Regression F-Score:\", round(lg_fscore, 3))\n",
    "print(\"Logistic Regression AUC:\", round(lg_roc_auc, 3))\n",
    "print('\\n\\n')\n",
    "# display ROC curve\n",
    "auc_visualization(y_test, lg_predicted_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:49:32.694032Z",
     "iopub.status.busy": "2022-02-16T14:49:32.693607Z",
     "iopub.status.idle": "2022-02-16T14:49:45.184414Z",
     "shell.execute_reply": "2022-02-16T14:49:45.183717Z",
     "shell.execute_reply.started": "2022-02-16T14:49:32.693993Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "lg_param_grid_1 = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                   'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                   'C': [0.01, 0.1, 1, 10, 100],\n",
    "                   }\n",
    "\n",
    "# search algorithm\n",
    "lg_search_1 = GridSearchCV(lg_model,\n",
    "                           lg_param_grid_1,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "lg_tune_result_1 = lg_search_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:49:58.360210Z",
     "iopub.status.busy": "2022-02-16T14:49:58.359382Z",
     "iopub.status.idle": "2022-02-16T14:49:58.365543Z",
     "shell.execute_reply": "2022-02-16T14:49:58.364615Z",
     "shell.execute_reply.started": "2022-02-16T14:49:58.360168Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', lg_tune_result_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:55:07.282771Z",
     "iopub.status.busy": "2022-02-16T14:55:07.282344Z",
     "iopub.status.idle": "2022-02-16T14:55:09.464532Z",
     "shell.execute_reply": "2022-02-16T14:55:09.462537Z",
     "shell.execute_reply.started": "2022-02-16T14:55:07.282735Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "lg_param_grid_2 = {'solver': ['saga'],\n",
    "                   'penalty': ['l1'],\n",
    "                   'C': [30, 40, 60, 80, 100, 120, 130],\n",
    "                   }\n",
    "\n",
    "# search algorithm\n",
    "lg_search_2 = GridSearchCV(lg_model,\n",
    "                           lg_param_grid_2,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "lg_tune_result_2 = lg_search_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:55:13.819324Z",
     "iopub.status.busy": "2022-02-16T14:55:13.818769Z",
     "iopub.status.idle": "2022-02-16T14:55:13.824414Z",
     "shell.execute_reply": "2022-02-16T14:55:13.823563Z",
     "shell.execute_reply.started": "2022-02-16T14:55:13.819287Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', lg_tune_result_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:55:50.949202Z",
     "iopub.status.busy": "2022-02-16T14:55:50.948705Z",
     "iopub.status.idle": "2022-02-16T14:55:52.527921Z",
     "shell.execute_reply": "2022-02-16T14:55:52.526935Z",
     "shell.execute_reply.started": "2022-02-16T14:55:50.949169Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "lg_param_grid_3 = {'solver': ['saga'],\n",
    "                   'penalty': ['l1'],\n",
    "                   'C': [15, 20, 25, 30, 35],\n",
    "                   }\n",
    "# search algorithm\n",
    "lg_search_3 = GridSearchCV(lg_model,\n",
    "                           lg_param_grid_3,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "lg_tune_result_3 = lg_search_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:55:56.246882Z",
     "iopub.status.busy": "2022-02-16T14:55:56.246168Z",
     "iopub.status.idle": "2022-02-16T14:55:56.251612Z",
     "shell.execute_reply": "2022-02-16T14:55:56.250782Z",
     "shell.execute_reply.started": "2022-02-16T14:55:56.246835Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', lg_tune_result_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:58:40.080290Z",
     "iopub.status.busy": "2022-02-16T14:58:40.079421Z",
     "iopub.status.idle": "2022-02-16T14:58:43.126686Z",
     "shell.execute_reply": "2022-02-16T14:58:43.125591Z",
     "shell.execute_reply.started": "2022-02-16T14:58:40.080240Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "lg_param_grid_4 = {'solver': ['saga'],\n",
    "                   'penalty': ['l1'],\n",
    "                   'C': [26,27,28,29,30,31,32,33,34],\n",
    "                   }\n",
    "# search algorithm\n",
    "lg_search_4 = GridSearchCV(lg_model,\n",
    "                           lg_param_grid_4,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "lg_tune_result_4 = lg_search_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:59:06.619180Z",
     "iopub.status.busy": "2022-02-16T14:59:06.618349Z",
     "iopub.status.idle": "2022-02-16T14:59:06.624216Z",
     "shell.execute_reply": "2022-02-16T14:59:06.623156Z",
     "shell.execute_reply.started": "2022-02-16T14:59:06.619135Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', lg_tune_result_4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:59:33.910097Z",
     "iopub.status.busy": "2022-02-16T14:59:33.909813Z",
     "iopub.status.idle": "2022-02-16T14:59:33.918528Z",
     "shell.execute_reply": "2022-02-16T14:59:33.917721Z",
     "shell.execute_reply.started": "2022-02-16T14:59:33.910067Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Best score 1st:', lg_tune_result_1.best_score_)\n",
    "print('Best score 2nd:', lg_tune_result_2.best_score_)\n",
    "print('Best score 3rd:', lg_tune_result_3.best_score_)\n",
    "print('Best score 4th:', lg_tune_result_4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After four iteration, the hyperparameter 'C':30  didn't change since the 2nd iteration. We decided to stop the iteration, and use best hyperparameter as found by the 4th iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3. Model Comparison After Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:01:31.611578Z",
     "iopub.status.busy": "2022-02-16T15:01:31.611262Z",
     "iopub.status.idle": "2022-02-16T15:01:32.178926Z",
     "shell.execute_reply": "2022-02-16T15:01:32.178040Z",
     "shell.execute_reply.started": "2022-02-16T15:01:31.611546Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "new_lg_model = LogisticRegression(random_state=0,\n",
    "                                  **lg_tune_result_4.best_params_)\n",
    "\n",
    "# train the model\n",
    "new_lg_result = new_lg_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "new_lg_predicted = new_lg_result.predict(X_test)\n",
    "new_lg_predicted_proba = new_lg_result.predict_proba(X_test)\n",
    "new_lg_predicted_proba = [i[1] for i in new_lg_predicted_proba]\n",
    "\n",
    "# confusion matrix\n",
    "new_lg_conf_mat = confusion_matrix(y_true = y_test, y_pred = new_lg_predicted)\n",
    "print(\"New Logistic Regression Confusion Matrix:\")\n",
    "print(new_lg_conf_mat)\n",
    "print('\\n\\n')\n",
    "# display confusion matrix heatmap\n",
    "confusion_matrix_heatmap(new_lg_conf_mat)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Evaluation\n",
    "new_lg_accuracy = accuracy_score(y_true = y_test, y_pred = new_lg_predicted)\n",
    "new_lg_fscore = f1_score(y_true = y_test, y_pred = new_lg_predicted)\n",
    "new_lg_roc_auc = roc_auc_score(y_true = y_test, y_score = new_lg_predicted_proba)\n",
    "print(\"New Logistic Regression Accuracy:\", round(new_lg_accuracy,4))\n",
    "print(\"New Logistic Regression F-Score:\", round(new_lg_fscore, 4))\n",
    "print(\"New Logistic Regression AUC:\", round(new_lg_roc_auc, 4))\n",
    "print('\\n\\n')\n",
    "# display ROC curve\n",
    "auc_visualization(y_test, new_lg_predicted_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:01:53.730747Z",
     "iopub.status.busy": "2022-02-16T15:01:53.730443Z",
     "iopub.status.idle": "2022-02-16T15:01:53.740683Z",
     "shell.execute_reply": "2022-02-16T15:01:53.739473Z",
     "shell.execute_reply.started": "2022-02-16T15:01:53.730718Z"
    }
   },
   "outputs": [],
   "source": [
    "# comparison\n",
    "print(\"Logistic Regression Accuracy:\", round(lg_accuracy,4))\n",
    "print(\"Logistic Regression F-Score:\", round(lg_fscore, 4))\n",
    "print(\"Logistic Regression AUC:\", round(lg_roc_auc, 4))\n",
    "print('===')\n",
    "print(\"New Logistic Regression Accuracy:\", round(new_lg_accuracy,4))\n",
    "print(\"New Logistic Regression F-Score:\", round(new_lg_fscore, 4))\n",
    "print(\"New Logistic Regression AUC:\", round(new_lg_roc_auc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:02:39.201791Z",
     "iopub.status.busy": "2022-02-16T15:02:39.201076Z",
     "iopub.status.idle": "2022-02-16T15:02:39.206313Z",
     "shell.execute_reply": "2022-02-16T15:02:39.205408Z",
     "shell.execute_reply.started": "2022-02-16T15:02:39.201754Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:03:44.400802Z",
     "iopub.status.busy": "2022-02-16T15:03:44.400506Z",
     "iopub.status.idle": "2022-02-16T15:03:45.020416Z",
     "shell.execute_reply": "2022-02-16T15:03:45.019388Z",
     "shell.execute_reply.started": "2022-02-16T15:03:44.400773Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# train the model\n",
    "knn_result = knn_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "knn_predicted = knn_result.predict(X_test)\n",
    "knn_predicted_proba = knn_result.predict_proba(X_test)\n",
    "knn_predicted_proba = [i[1] for i in knn_predicted_proba]\n",
    "\n",
    "# confusion matrix\n",
    "knn_conf_mat = confusion_matrix(y_true = y_test, y_pred = knn_predicted)\n",
    "print(\"k-NN Confusion Matrix:\")\n",
    "print(knn_conf_mat)\n",
    "print('\\n\\n')\n",
    "# display confusion matrix heatmap\n",
    "confusion_matrix_heatmap(knn_conf_mat)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Evaluation\n",
    "knn_accuracy = accuracy_score(y_true = y_test, y_pred = knn_predicted)\n",
    "knn_fscore = f1_score(y_true = y_test, y_pred = knn_predicted)\n",
    "knn_roc_auc = roc_auc_score(y_true = y_test, y_score = knn_predicted_proba)\n",
    "print(\"k-NN Accuracy:\", round(knn_accuracy,3))\n",
    "print(\"k-NN F-Score:\", round(knn_fscore, 3))\n",
    "print(\"k-NN AUC:\", round(knn_roc_auc, 3))\n",
    "print('\\n\\n')\n",
    "# display ROC curve\n",
    "auc_visualization(y_test, knn_predicted_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:07:06.640666Z",
     "iopub.status.busy": "2022-02-16T15:07:06.640320Z",
     "iopub.status.idle": "2022-02-16T15:08:17.689171Z",
     "shell.execute_reply": "2022-02-16T15:08:17.687540Z",
     "shell.execute_reply.started": "2022-02-16T15:07:06.640630Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "knn_param_grid_1 = {'n_neighbors': list(range(1,22,2)),\n",
    "                    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "                    'weights': ['uniform', 'distance'],\n",
    "                    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                    }\n",
    "\n",
    "# search algorithm\n",
    "knn_search_1 = GridSearchCV(knn_model,\n",
    "                           knn_param_grid_1,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "knn_tune_result_1 = knn_search_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:08:23.611046Z",
     "iopub.status.busy": "2022-02-16T15:08:23.610747Z",
     "iopub.status.idle": "2022-02-16T15:08:23.616507Z",
     "shell.execute_reply": "2022-02-16T15:08:23.615501Z",
     "shell.execute_reply.started": "2022-02-16T15:08:23.611011Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', knn_tune_result_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:10:20.280580Z",
     "iopub.status.busy": "2022-02-16T15:10:20.280236Z",
     "iopub.status.idle": "2022-02-16T15:10:24.779698Z",
     "shell.execute_reply": "2022-02-16T15:10:24.777968Z",
     "shell.execute_reply.started": "2022-02-16T15:10:20.280547Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "knn_param_grid_2 = {'n_neighbors': list(range(21,50,2)),\n",
    "                    'metric': ['manhattan'],\n",
    "                    'weights': ['distance'],\n",
    "                    'algorithm': ['auto'],\n",
    "                    }\n",
    "\n",
    "# search algorithm\n",
    "knn_search_2 = GridSearchCV(knn_model,\n",
    "                           knn_param_grid_2,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "knn_tune_result_2 = knn_search_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:10:27.756625Z",
     "iopub.status.busy": "2022-02-16T15:10:27.756082Z",
     "iopub.status.idle": "2022-02-16T15:10:27.761235Z",
     "shell.execute_reply": "2022-02-16T15:10:27.760381Z",
     "shell.execute_reply.started": "2022-02-16T15:10:27.756588Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', knn_tune_result_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:11:37.623797Z",
     "iopub.status.busy": "2022-02-16T15:11:37.623248Z",
     "iopub.status.idle": "2022-02-16T15:11:42.237164Z",
     "shell.execute_reply": "2022-02-16T15:11:42.236013Z",
     "shell.execute_reply.started": "2022-02-16T15:11:37.623756Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "knn_param_grid_3 = {'n_neighbors': [45,47,49,51,52,53],\n",
    "                    'metric': ['manhattan'],\n",
    "                    'weights': ['distance'],\n",
    "                    'algorithm': ['auto'],\n",
    "                    }\n",
    "\n",
    "# search algorithm\n",
    "knn_search_3 = GridSearchCV(knn_model,\n",
    "                           knn_param_grid_3,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "knn_tune_result_3 = knn_search_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:11:45.552900Z",
     "iopub.status.busy": "2022-02-16T15:11:45.552485Z",
     "iopub.status.idle": "2022-02-16T15:11:45.557282Z",
     "shell.execute_reply": "2022-02-16T15:11:45.556349Z",
     "shell.execute_reply.started": "2022-02-16T15:11:45.552870Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', knn_tune_result_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:11:51.131203Z",
     "iopub.status.busy": "2022-02-16T15:11:51.130662Z",
     "iopub.status.idle": "2022-02-16T15:11:51.138568Z",
     "shell.execute_reply": "2022-02-16T15:11:51.137379Z",
     "shell.execute_reply.started": "2022-02-16T15:11:51.131169Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Best score 1st:', knn_tune_result_1.best_score_)\n",
    "print('Best score 2nd:', knn_tune_result_2.best_score_)\n",
    "print('Best score 3rd:', knn_tune_result_3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "use hyperparameters as found by 3rd iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. Model Comparison After Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:12:33.306055Z",
     "iopub.status.busy": "2022-02-16T15:12:33.305743Z",
     "iopub.status.idle": "2022-02-16T15:12:34.113601Z",
     "shell.execute_reply": "2022-02-16T15:12:34.112657Z",
     "shell.execute_reply.started": "2022-02-16T15:12:33.306022Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "new_knn_model = KNeighborsClassifier(**knn_tune_result_3.best_params_)\n",
    "\n",
    "# train the model\n",
    "new_knn_result = new_knn_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "new_knn_predicted = new_knn_result.predict(X_test)\n",
    "new_knn_predicted_proba = new_knn_result.predict_proba(X_test)\n",
    "new_knn_predicted_proba = [i[1] for i in new_knn_predicted_proba]\n",
    "\n",
    "# confusion matrix\n",
    "new_knn_conf_mat = confusion_matrix(y_true = y_test, y_pred = new_knn_predicted)\n",
    "print(\"New k-NN Confusion Matrix:\")\n",
    "print(new_knn_conf_mat)\n",
    "print('\\n\\n')\n",
    "# display confusion matrix heatmap\n",
    "confusion_matrix_heatmap(new_knn_conf_mat)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Evaluation\n",
    "new_knn_accuracy = accuracy_score(y_true = y_test, y_pred = new_knn_predicted)\n",
    "new_knn_fscore = f1_score(y_true = y_test, y_pred = new_knn_predicted)\n",
    "new_knn_roc_auc = roc_auc_score(y_true = y_test, y_score = new_knn_predicted_proba)\n",
    "print(\"New k-NN Accuracy:\", round(new_knn_accuracy,3))\n",
    "print(\"New k-NN F-Score:\", round(new_knn_fscore, 3))\n",
    "print(\"New k-NN AUC:\", round(new_knn_roc_auc, 3))\n",
    "print('\\n\\n')\n",
    "# display ROC curve\n",
    "auc_visualization(y_test, new_knn_predicted_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:12:46.142614Z",
     "iopub.status.busy": "2022-02-16T15:12:46.142312Z",
     "iopub.status.idle": "2022-02-16T15:12:46.151310Z",
     "shell.execute_reply": "2022-02-16T15:12:46.150253Z",
     "shell.execute_reply.started": "2022-02-16T15:12:46.142584Z"
    }
   },
   "outputs": [],
   "source": [
    "# comparison\n",
    "print(\"k-NN Accuracy:\", round(knn_accuracy,4))\n",
    "print(\"k-NN F-Score:\", round(knn_fscore, 4))\n",
    "print(\"k-NN AUC:\", round(knn_roc_auc, 4))\n",
    "print('===')\n",
    "print(\"New k-NN Accuracy:\", round(new_knn_accuracy,4))\n",
    "print(\"New k-NN F-Score:\", round(new_knn_fscore, 4))\n",
    "print(\"New k-NN AUC:\", round(new_knn_roc_auc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned model AUC score is higher than the default model's, but the F-Score is not. It is because the 'scoring' parameter on GridSearchCV is set to 'roc_auc' as we want to predict the probability of the churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:13:04.193367Z",
     "iopub.status.busy": "2022-02-16T15:13:04.193059Z",
     "iopub.status.idle": "2022-02-16T15:13:04.254875Z",
     "shell.execute_reply": "2022-02-16T15:13:04.254214Z",
     "shell.execute_reply.started": "2022-02-16T15:13:04.193330Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:13:50.552227Z",
     "iopub.status.busy": "2022-02-16T15:13:50.551768Z",
     "iopub.status.idle": "2022-02-16T15:13:51.855759Z",
     "shell.execute_reply": "2022-02-16T15:13:51.854972Z",
     "shell.execute_reply.started": "2022-02-16T15:13:50.552194Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# train the model\n",
    "rf_result = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "rf_predicted = rf_result.predict(X_test)\n",
    "rf_predicted_proba = rf_result.predict_proba(X_test)\n",
    "rf_predicted_proba = [i[1] for i in rf_predicted_proba]\n",
    "\n",
    "# confusion matrix\n",
    "rf_conf_mat = confusion_matrix(y_true = y_test, y_pred = rf_predicted)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(rf_conf_mat)\n",
    "print('\\n\\n')\n",
    "# display confusion matrix heatmap\n",
    "confusion_matrix_heatmap(rf_conf_mat)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Evaluation\n",
    "rf_accuracy = accuracy_score(y_true = y_test, y_pred = rf_predicted)\n",
    "rf_fscore = f1_score(y_true = y_test, y_pred = rf_predicted)\n",
    "rf_roc_auc = roc_auc_score(y_true = y_test, y_score = rf_predicted_proba)\n",
    "print(\"Random Forest Accuracy:\", round(rf_accuracy,3))\n",
    "print(\"Random Forest F-Score:\", round(rf_fscore, 3))\n",
    "print(\"Random Forest AUC:\", round(rf_roc_auc, 3))\n",
    "print('\\n\\n')\n",
    "# display ROC curve\n",
    "auc_visualization(y_test, rf_predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:19:06.482335Z",
     "iopub.status.busy": "2022-02-16T15:19:06.482039Z",
     "iopub.status.idle": "2022-02-16T15:41:49.836442Z",
     "shell.execute_reply": "2022-02-16T15:41:49.835607Z",
     "shell.execute_reply.started": "2022-02-16T15:19:06.482302Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "rf_param_grid_1 = {'n_estimators': [10,100,1000],\n",
    "                   'max_depth': [5, 10, 15],\n",
    "                   'min_samples_split': [2,3,4,5],\n",
    "                   'min_samples_leaf': [1,2,3],\n",
    "                   'max_features': ['auto','sqrt','log2']\n",
    "                   }\n",
    "\n",
    "# search algorithm\n",
    "rf_search_1 = GridSearchCV(rf_model,\n",
    "                           rf_param_grid_1,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "rf_tune_result_1 = rf_search_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T15:48:55.313436Z",
     "iopub.status.busy": "2022-02-16T15:48:55.312878Z",
     "iopub.status.idle": "2022-02-16T15:48:55.321190Z",
     "shell.execute_reply": "2022-02-16T15:48:55.320168Z",
     "shell.execute_reply.started": "2022-02-16T15:48:55.313398Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', rf_tune_result_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:03:18.631822Z",
     "iopub.status.busy": "2022-02-16T16:03:18.631487Z",
     "iopub.status.idle": "2022-02-16T16:06:15.904145Z",
     "shell.execute_reply": "2022-02-16T16:06:15.903212Z",
     "shell.execute_reply.started": "2022-02-16T16:03:18.631790Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "rf_param_grid_2 = {'n_estimators': [900, 1000, 1100, 1200],\n",
    "                   'max_depth': [14, 15, 16],\n",
    "                   'min_samples_split': [2],\n",
    "                   'min_samples_leaf': [1],\n",
    "                   'max_features': ['auto']\n",
    "                   }\n",
    "\n",
    "\n",
    "# search algorithm\n",
    "rf_search_2 = GridSearchCV(rf_model,\n",
    "                           rf_param_grid_2,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "rf_tune_result_2 = rf_search_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:06:15.905799Z",
     "iopub.status.busy": "2022-02-16T16:06:15.905590Z",
     "iopub.status.idle": "2022-02-16T16:06:15.911565Z",
     "shell.execute_reply": "2022-02-16T16:06:15.910536Z",
     "shell.execute_reply.started": "2022-02-16T16:06:15.905774Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', rf_tune_result_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:12:58.061602Z",
     "iopub.status.busy": "2022-02-16T16:12:58.060981Z",
     "iopub.status.idle": "2022-02-16T16:13:41.733001Z",
     "shell.execute_reply": "2022-02-16T16:13:41.731901Z",
     "shell.execute_reply.started": "2022-02-16T16:12:58.061559Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "rf_param_grid_3 = {'n_estimators': [700, 800, 900],\n",
    "                   'max_depth': [15],\n",
    "                   'min_samples_split': [2],\n",
    "                   'min_samples_leaf': [1],\n",
    "                   'max_features': ['auto']\n",
    "                   }\n",
    "\n",
    "# search algorithm\n",
    "rf_search_3 = GridSearchCV(rf_model,\n",
    "                           rf_param_grid_3,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "rf_tune_result_3 = rf_search_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:08:18.596942Z",
     "iopub.status.busy": "2022-02-16T16:08:18.596650Z",
     "iopub.status.idle": "2022-02-16T16:08:18.602124Z",
     "shell.execute_reply": "2022-02-16T16:08:18.601110Z",
     "shell.execute_reply.started": "2022-02-16T16:08:18.596909Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', rf_tune_result_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:28:32.058023Z",
     "iopub.status.busy": "2022-02-16T16:28:32.057240Z",
     "iopub.status.idle": "2022-02-16T16:30:15.592743Z",
     "shell.execute_reply": "2022-02-16T16:30:15.591696Z",
     "shell.execute_reply.started": "2022-02-16T16:28:32.057968Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "rf_param_grid_4 = {'n_estimators': [840, 860, 880, 900],\n",
    "                   'max_depth': [15],\n",
    "                   'min_samples_split': [2],\n",
    "                   'min_samples_leaf': [1],\n",
    "                   'max_features': ['auto'],\n",
    "                   'criterion': ['gini','entropy']  #new hyperparameter addition\n",
    "                   }\n",
    "\n",
    "# search algorithm\n",
    "rf_search_4 = GridSearchCV(rf_model,\n",
    "                           rf_param_grid_4,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "rf_tune_result_4 = rf_search_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:30:23.789258Z",
     "iopub.status.busy": "2022-02-16T16:30:23.788969Z",
     "iopub.status.idle": "2022-02-16T16:30:23.794215Z",
     "shell.execute_reply": "2022-02-16T16:30:23.793597Z",
     "shell.execute_reply.started": "2022-02-16T16:30:23.789223Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', rf_tune_result_4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5th Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:31:09.657857Z",
     "iopub.status.busy": "2022-02-16T16:31:09.657006Z",
     "iopub.status.idle": "2022-02-16T16:33:07.521940Z",
     "shell.execute_reply": "2022-02-16T16:33:07.521098Z",
     "shell.execute_reply.started": "2022-02-16T16:31:09.657804Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "rf_param_grid_5 = {'n_estimators': [890, 895,900, 905],\n",
    "                   'max_depth': [15],\n",
    "                   'min_samples_split': [2],\n",
    "                   'min_samples_leaf': [1],\n",
    "                   'max_features': ['auto'],\n",
    "                   'criterion': ['entropy']\n",
    "                   }\n",
    "\n",
    "# search algorithm\n",
    "rf_search_5 = GridSearchCV(rf_model,\n",
    "                           rf_param_grid_5,\n",
    "                           scoring = 'roc_auc',\n",
    "                           cv = 10,\n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# train\n",
    "rf_tune_result_5 = rf_search_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:33:12.220103Z",
     "iopub.status.busy": "2022-02-16T16:33:12.219202Z",
     "iopub.status.idle": "2022-02-16T16:33:12.225463Z",
     "shell.execute_reply": "2022-02-16T16:33:12.224759Z",
     "shell.execute_reply.started": "2022-02-16T16:33:12.220048Z"
    }
   },
   "outputs": [],
   "source": [
    "# best hyperparameter\n",
    "print('Best hyperparameter:', rf_tune_result_5.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:33:23.040802Z",
     "iopub.status.busy": "2022-02-16T16:33:23.040503Z",
     "iopub.status.idle": "2022-02-16T16:33:23.050749Z",
     "shell.execute_reply": "2022-02-16T16:33:23.049520Z",
     "shell.execute_reply.started": "2022-02-16T16:33:23.040770Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Best score 1st:', rf_tune_result_1.best_score_)\n",
    "print('Best score 2nd:', rf_tune_result_2.best_score_)\n",
    "print('Best score 3rd:', rf_tune_result_3.best_score_)\n",
    "print('Best score 4th:', rf_tune_result_4.best_score_)\n",
    "print('Best score 5th:', rf_tune_result_5.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "The hyperparameters at 4th iteration gives the best score, thus we will use it as our new model hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3. Model Comparison After Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:36:15.636856Z",
     "iopub.status.busy": "2022-02-16T16:36:15.635883Z",
     "iopub.status.idle": "2022-02-16T16:36:24.479690Z",
     "shell.execute_reply": "2022-02-16T16:36:24.478779Z",
     "shell.execute_reply.started": "2022-02-16T16:36:15.636817Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "new_rf_model = RandomForestClassifier(random_state=0, **rf_tune_result_4.best_params_)\n",
    "\n",
    "# train the model\n",
    "new_rf_result = new_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "new_rf_predicted = new_rf_result.predict(X_test)\n",
    "new_rf_predicted_proba = new_rf_result.predict_proba(X_test)\n",
    "new_rf_predicted_proba = [i[1] for i in new_rf_predicted_proba]\n",
    "\n",
    "# confusion matrix\n",
    "new_rf_conf_mat = confusion_matrix(y_true = y_test, y_pred = new_rf_predicted)\n",
    "print(\"New Random Forest Confusion Matrix:\")\n",
    "print(new_rf_conf_mat)\n",
    "print('\\n\\n')\n",
    "# display confusion matrix heatmap\n",
    "confusion_matrix_heatmap(new_rf_conf_mat)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "# Evaluation\n",
    "new_rf_accuracy = accuracy_score(y_true = y_test, y_pred = new_rf_predicted)\n",
    "new_rf_fscore = f1_score(y_true = y_test, y_pred = new_rf_predicted)\n",
    "new_rf_roc_auc = roc_auc_score(y_true = y_test, y_score = new_rf_predicted_proba)\n",
    "print(\"New Random Forest Accuracy:\", round(new_rf_accuracy,3))\n",
    "print(\"New Random Forest F-Score:\", round(new_rf_fscore, 3))\n",
    "print(\"New Random Forest AUC:\", round(new_rf_roc_auc, 3))\n",
    "print('\\n\\n')\n",
    "# display ROC curve\n",
    "auc_visualization(y_test, new_rf_predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:37:27.525566Z",
     "iopub.status.busy": "2022-02-16T16:37:27.525224Z",
     "iopub.status.idle": "2022-02-16T16:37:27.534513Z",
     "shell.execute_reply": "2022-02-16T16:37:27.533479Z",
     "shell.execute_reply.started": "2022-02-16T16:37:27.525533Z"
    }
   },
   "outputs": [],
   "source": [
    "# comparison\n",
    "print(\"Random Forest Accuracy:\", round(rf_accuracy,4))\n",
    "print(\"Random Forest F-Score:\", round(rf_fscore, 4))\n",
    "print(\"Random Forest AUC:\", round(rf_roc_auc, 4))\n",
    "print('===')\n",
    "print(\"New Random Forest Accuracy:\", round(new_rf_accuracy,4))\n",
    "print(\"New Random Forest F-Score:\", round(new_rf_fscore, 4))\n",
    "print(\"New Random Forest AUC:\", round(new_rf_roc_auc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "The model which has the best AUC score for our data is Random Forest, followed by Logistic Regression, and then k-NN in the last place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:39:25.110706Z",
     "iopub.status.busy": "2022-02-16T16:39:25.109812Z",
     "iopub.status.idle": "2022-02-16T16:39:25.117026Z",
     "shell.execute_reply": "2022-02-16T16:39:25.115905Z",
     "shell.execute_reply.started": "2022-02-16T16:39:25.110658Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"New Logistic Regression AUC:\", round(new_lg_roc_auc, 4))\n",
    "print(\"New k-NN AUC:\", round(new_knn_roc_auc, 4))\n",
    "print(\"New Random Forest AUC:\", round(new_rf_roc_auc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:47:51.537971Z",
     "iopub.status.busy": "2022-02-16T16:47:51.537151Z",
     "iopub.status.idle": "2022-02-16T16:47:51.618221Z",
     "shell.execute_reply": "2022-02-16T16:47:51.617293Z",
     "shell.execute_reply.started": "2022-02-16T16:47:51.537924Z"
    }
   },
   "outputs": [],
   "source": [
    "new_rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T16:53:36.370218Z",
     "iopub.status.busy": "2022-02-16T16:53:36.369308Z",
     "iopub.status.idle": "2022-02-16T16:53:36.375828Z",
     "shell.execute_reply": "2022-02-16T16:53:36.374905Z",
     "shell.execute_reply.started": "2022-02-16T16:53:36.370170Z"
    }
   },
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:03:02.617981Z",
     "iopub.status.busy": "2022-02-16T17:03:02.617147Z",
     "iopub.status.idle": "2022-02-16T17:03:02.700843Z",
     "shell.execute_reply": "2022-02-16T17:03:02.699907Z",
     "shell.execute_reply.started": "2022-02-16T17:03:02.617939Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature importance dataframe\n",
    "feat_imp = pd.DataFrame({'Feature': X.columns,\n",
    "                         'Importance': new_rf_model.feature_importances_})\n",
    "feat_imp_sort = feat_imp.sort_values(by='Importance', ascending=False)\n",
    "feat_imp_sort\n",
    "\n",
    "# feature importance bar plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T17:06:43.285074Z",
     "iopub.status.busy": "2022-02-16T17:06:43.284779Z",
     "iopub.status.idle": "2022-02-16T17:06:43.517284Z",
     "shell.execute_reply": "2022-02-16T17:06:43.516369Z",
     "shell.execute_reply.started": "2022-02-16T17:06:43.285037Z"
    }
   },
   "outputs": [],
   "source": [
    "# display as figure\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.barplot(x=feat_imp_sort['Importance'], y=feat_imp_sort['Feature'], color='#a2c9f4')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
